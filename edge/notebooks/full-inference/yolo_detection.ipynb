{
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "device_requirements": {
            "min_memory": "8GB",
            "gpu_required": true,
            "min_cuda_capability": "5.0",
            "recommended_device_type": ["jetson-agx-orin", "jetson-nano"],
            "max_batch_size": 32
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4,
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# YOLO Object Detection - Full Inference\n",
                "\n",
                "This notebook demonstrates full-resolution object detection using YOLO on edge devices.\n",
                "Requires GPU support and minimum 8GB memory.\n",
                "\n",
                "## Device Compatibility\n",
                "- Fully compatible with Jetson AGX Orin\n",
                "- Compatible with Jetson Nano (with reduced batch size)\n",
                "- Not recommended for Raspberry Pi"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "import sys\n",
                "sys.path.append('../..')\n",
                "from base_config import DeviceConfig\n",
                "from monitoring import DeviceMonitor\n",
                "\n",
                "# Initialize device configuration\n",
                "config = DeviceConfig()\n",
                "monitor = DeviceMonitor()\n",
                "\n",
                "# Check device compatibility\n",
                "requirements = {\n",
                "    \"gpu_required\": True,\n",
                "    \"min_memory\": \"8GB\",\n",
                "    \"min_cuda_capability\": \"5.0\"\n",
                "}\n",
                "\n",
                "if not config.check_notebook_compatibility(requirements):\n",
                "    raise RuntimeError(\"Device does not meet minimum requirements for this notebook\")\n",
                "\n",
                "print(f\"Device {config.device_type} is compatible with this notebook\")\n",
                "print(\"Available features:\", config.get_device_features())\n"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "# Import required libraries\n",
                "import torch\n",
                "from ultralytics import YOLO\n",
                "import cv2\n",
                "import numpy as np\n",
                "from supervision import BoxAnnotator, VideoInfo\n",
                "\n",
                "# Load optimized model based on device type\n",
                "model = YOLO('yolov8n.pt')\n",
                "\n",
                "# Set device-specific parameters\n",
                "batch_size = config.get_optimized_batch_size()\n",
                "print(f\"Using optimized batch size: {batch_size}\")\n"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "# Function for inference\n",
                "def process_frame(frame):\n",
                "    results = model(frame)[0]\n",
                "    return results\n",
                "\n",
                "# Example usage with monitoring\n",
                "def run_inference(video_path):\n",
                "    cap = cv2.VideoCapture(video_path)\n",
                "    box_annotator = BoxAnnotator()\n",
                "    \n",
                "    while cap.isOpened():\n",
                "        ret, frame = cap.read()\n",
                "        if not ret:\n",
                "            break\n",
                "            \n",
                "        # Get system metrics before inference\n",
                "        metrics = monitor.collect_metrics()\n",
                "        \n",
                "        # Run inference\n",
                "        results = process_frame(frame)\n",
                "        \n",
                "        # Check resource usage\n",
                "        warnings = monitor.check_thresholds(metrics)\n",
                "        if warnings:\n",
                "            print(\"Resource warnings:\", warnings)\n",
                "            \n",
                "    cap.release()\n"
            ],
            "execution_count": null,
            "outputs": []
        }
    ]
}
