{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enhanced Marine Science Object Detection\n",
    "## System Information and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "import psutil\n",
    "import os\n",
    "from datetime import datetime\n",
    "import json\n",
    "import socket\n",
    "\n",
    "class DateTimeEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, datetime):\n",
    "            return obj.isoformat()\n",
    "        return super().default(obj)\n",
    "\n",
    "def get_system_info():\n",
    "    system_info = {\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        'architecture': platform.machine(),\n",
    "        'processor': platform.processor(),\n",
    "        'platform': platform.platform(),\n",
    "        'python_version': platform.python_version(),\n",
    "        'hostname': socket.gethostname(),\n",
    "        'total_memory_gb': round(psutil.virtual_memory().total / (1024**3), 2),\n",
    "        'available_memory_gb': round(psutil.virtual_memory().available / (1024**3), 2),\n",
    "        'cpu_count': psutil.cpu_count(),\n",
    "        'cpu_percent': psutil.cpu_percent(interval=1),\n",
    "        'docker_container_id': os.environ.get('HOSTNAME', 'Not in container')\n",
    "    }\n",
    "    return system_info\n",
    "\n",
    "# Get and display system information\n",
    "system_info = get_system_info()\n",
    "print(\"=== System Information ===\")\n",
    "for key, value in system_info.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "# Save system information to file\n",
    "with open('system_info.json', 'w') as f:\n",
    "    json.dump(system_info, f, indent=4, cls=DateTimeEncoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resource Check and Error Handling\n",
    "def check_system_resources(min_memory_gb=4, min_cpu_cores=2):\n",
    "    try:\n",
    "        memory_gb = psutil.virtual_memory().available / (1024**3)\n",
    "        cpu_cores = psutil.cpu_count()\n",
    "        \n",
    "        issues = []\n",
    "        if memory_gb < min_memory_gb:\n",
    "            issues.append(f\"Warning: Available memory ({memory_gb:.1f}GB) is below recommended minimum ({min_memory_gb}GB)\")\n",
    "        if cpu_cores < min_cpu_cores:\n",
    "            issues.append(f\"Warning: Available CPU cores ({cpu_cores}) is below recommended minimum ({min_cpu_cores})\")\n",
    "        \n",
    "        if issues:\n",
    "            print(\"\\nResource Check Warnings:\")\n",
    "            for issue in issues:\n",
    "                print(f\"- {issue}\")\n",
    "            print(\"\\nRecommendations:\")\n",
    "            print(\"- Close unnecessary applications\")\n",
    "            print(\"- Consider reducing batch size or image resolution\")\n",
    "            return False\n",
    "        else:\n",
    "            print(\"\\nSystem resources meet minimum requirements\")\n",
    "            return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error checking system resources: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "# Perform resource check\n",
    "check_system_resources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries with error handling\n",
    "def import_required_libraries():\n",
    "    try:\n",
    "        global cv2, np, Image, display, clear_output, tqdm, InferenceHTTPClient\n",
    "        from inference_sdk import InferenceHTTPClient\n",
    "        import cv2\n",
    "        import numpy as np\n",
    "        from IPython.display import Image, display, clear_output\n",
    "        from tqdm.notebook import tqdm\n",
    "        print(\"All required libraries successfully imported\")\n",
    "        return True\n",
    "    except ImportError as e:\n",
    "        print(f\"Error importing required libraries: {str(e)}\")\n",
    "        print(\"\\nPlease install missing libraries using:\")\n",
    "        print(\"pip install inference-sdk opencv-python numpy ipython tqdm\")\n",
    "        return False\n",
    "\n",
    "# Import libraries\n",
    "if not import_required_libraries():\n",
    "    raise SystemExit(\"Required libraries not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video Processing Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced Configuration Class\n",
    "class VideoConfig:\n",
    "    def __init__(self, source_path, model_id, confidence=0.3, fps_limit=10):\n",
    "        self.source_path = source_path\n",
    "        self.model_id = model_id\n",
    "        self.confidence = confidence\n",
    "        self.fps_limit = fps_limit\n",
    "        self.start_time = None\n",
    "        self.end_time = None\n",
    "        self.processing_stats = {\n",
    "            'frames_processed': 0,\n",
    "            'total_detections': 0,\n",
    "            'avg_confidence': 0,\n",
    "            'fps': 0,\n",
    "            'system_load': []\n",
    "        }\n",
    "\n",
    "    def to_dict(self):\n",
    "        return {\n",
    "            'source_path': self.source_path,\n",
    "            'model_id': self.model_id,\n",
    "            'confidence': self.confidence,\n",
    "            'fps_limit': self.fps_limit,\n",
    "            'start_time': self.start_time.isoformat() if self.start_time else None,\n",
    "            'end_time': self.end_time.isoformat() if self.end_time else None,\n",
    "            'processing_stats': self.processing_stats\n",
    "        }\n",
    "\n",
    "# Initialize configuration\n",
    "config = VideoConfig(\n",
    "    source_path=\"test_diver_video.mp4\",\n",
    "    model_id=\"fish-scuba-project/2\",\n",
    "    confidence=0.1,\n",
    "    fps_limit=5\n",
    ")\n",
    "\n",
    "print(\"Configuration initialized with:\")\n",
    "for key, value in vars(config).items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced draw_prediction function with timestamp and stats\n",
    "def draw_prediction(image, prediction, stats):\n",
    "    h, w = image.shape[:2]\n",
    "    x = prediction.get('x', 0.5)\n",
    "    y = prediction.get('y', 0.5)\n",
    "    width = prediction.get('width', 0)\n",
    "    height = prediction.get('height', 0)\n",
    "    \n",
    "    x1 = int((x - width/2) * w)\n",
    "    y1 = int((y - height/2) * h)\n",
    "    x2 = int((x + width/2) * w)\n",
    "    y2 = int((y + height/2) * h)\n",
    "    \n",
    "    x1, y1 = max(0, min(w-1, x1)), max(0, min(h-1, y1))\n",
    "    x2, y2 = max(0, min(w-1, x2)), max(0, min(h-1, y2))\n",
    "    \n",
    "    if x2 <= x1 or y2 <= y1:\n",
    "        return\n",
    "    \n",
    "    class_name = prediction.get('class', 'unknown')\n",
    "    confidence = prediction.get('confidence', 0)\n",
    "    \n",
    "    color = (0, 255, 0) if confidence > 0.7 else (0, 255, 255) if confidence > 0.4 else (0, 165, 255)\n",
    "    \n",
    "    # Draw bounding box and label\n",
    "    cv2.rectangle(image, (x1, y1), (x2, y2), color, 4)\n",
    "    \n",
    "    # Add timestamp and stats\n",
    "    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    cv2.putText(image, timestamp, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "    \n",
    "    # Add processing stats\n",
    "    stats_text = f\"FPS: {stats['fps']:.1f} | CPU: {stats['cpu_percent']}% | Mem: {stats['memory_percent']}%\"\n",
    "    cv2.putText(image, stats_text, (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced video processing function\n",
    "def process_video(config):\n",
    "    config.start_time = datetime.now()\n",
    "    results_data = []\n",
    "    \n",
    "    try:\n",
    "        cap = cv2.VideoCapture(config.source_path)\n",
    "        if not cap.isOpened():\n",
    "            raise Exception(f\"Could not open video source {config.source_path}\")\n",
    "        \n",
    "        # Video properties\n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        \n",
    "        with tqdm(total=total_frames, desc=\"Processing video\") as pbar:\n",
    "            while cap.isOpened():\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "                \n",
    "                # Get system stats\n",
    "                stats = {\n",
    "                    'timestamp': datetime.now().isoformat(),\n",
    "                    'cpu_percent': psutil.cpu_percent(),\n",
    "                    'memory_percent': psutil.virtual_memory().percent,\n",
    "                    'fps': fps\n",
    "                }\n",
    "                \n",
    "                # Process frame and collect results\n",
    "                try:\n",
    "                    result = CLIENT.infer(frame, model_id=config.model_id)\n",
    "                    \n",
    "                    # Store results\n",
    "                    frame_result = {\n",
    "                        'frame_number': config.processing_stats['frames_processed'],\n",
    "                        'timestamp': stats['timestamp'],\n",
    "                        'predictions': result.get('predictions', []),\n",
    "                        'system_stats': stats\n",
    "                    }\n",
    "                    results_data.append(frame_result)\n",
    "                    \n",
    "                    # Update processing stats\n",
    "                    config.processing_stats['frames_processed'] += 1\n",
    "                    if 'predictions' in result:\n",
    "                        config.processing_stats['total_detections'] += len(result['predictions'])\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing frame: {str(e)}\")\n",
    "                \n",
    "                pbar.update(1)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during video processing: {str(e)}\")\n",
    "    finally:\n",
    "        config.end_time = datetime.now()\n",
    "        cap.release()\n",
    "        \n",
    "        # Save results to file\n",
    "        results_summary = {\n",
    "            'system_info': get_system_info(),\n",
    "            'config': config.to_dict(),\n",
    "            'processing_stats': config.processing_stats,\n",
    "            'frame_results': results_data\n",
    "        }\n",
    "        \n",
    "        with open('processing_results.json', 'w') as f:\n",
    "            json.dump(results_summary, f, indent=4, cls=DateTimeEncoder)\n",
    "        \n",
    "        print(\"\\nProcessing Summary:\")\n",
    "        print(f\"Total frames processed: {config.processing_stats['frames_processed']}\")\n",
    "        print(f\"Total detections: {config.processing_stats['total_detections']}\")\n",
    "        print(f\"Processing time: {config.end_time - config.start_time}\")\n",
    "\n",
    "# Initialize client and run processing\n",
    "CLIENT = InferenceHTTPClient(\n",
    "    api_url=\"http://inference-server:9001\",\n",
    "    api_key=os.environ.get('ROBOFLOW_API_KEY')\n",
    ")\n",
    "\n",
    "# Run video processing\n",
    "process_video(config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
