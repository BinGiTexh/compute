{
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "device_requirements": {
            "min_memory": "2GB",
            "gpu_required": false,
            "min_cuda_capability": "0.0",
            "recommended_device_type": ["raspberry-pi", "jetson-nano"],
            "max_batch_size": 1
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4,
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# YOLO Object Detection - Light Inference\n",
                "\n",
                "This notebook demonstrates optimized, lightweight object detection using YOLO on edge devices.\n",
                "Optimized for devices with limited resources (2GB+ RAM, CPU-only support).\n",
                "\n",
                "## Device Compatibility\n",
                "- Compatible with Raspberry Pi\n",
                "- Compatible with Jetson Nano\n",
                "- Compatible with Jetson AGX Orin (but full-inference version recommended)\n",
                "\n",
                "## Optimizations\n",
                "- Uses quantized models\n",
                "- Reduced input resolution\n",
                "- Batch size of 1\n",
                "- Memory-efficient processing"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "import sys\n",
                "sys.path.append('../..')\n",
                "from base_config import DeviceConfig\n",
                "from monitoring import DeviceMonitor\n",
                "\n",
                "# Initialize device configuration\n",
                "config = DeviceConfig()\n",
                "monitor = DeviceMonitor()\n",
                "\n",
                "# Check device compatibility\n",
                "requirements = {\n",
                "    \"gpu_required\": False,\n",
                "    \"min_memory\": \"2GB\"\n",
                "}\n",
                "\n",
                "if not config.check_notebook_compatibility(requirements):\n",
                "    raise RuntimeError(\"Device does not meet minimum requirements for this notebook\")\n",
                "\n",
                "print(f\"Device {config.device_type} is compatible with this notebook\")\n",
                "print(\"Available features:\", config.get_device_features())\n"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "# Import required libraries\n",
                "import cv2\n",
                "import numpy as np\n",
                "from supervision import BoxAnnotator\n",
                "\n",
                "# Import appropriate inference backend based on device\n",
                "if config.device_type == 'raspberry-pi':\n",
                "    import tflite_runtime.interpreter as tflite\n",
                "    # Load quantized TFLite model\n",
                "    interpreter = tflite.Interpreter(model_path='models/yolov8n_quantized.tflite')\n",
                "    interpreter.allocate_tensors()\n",
                "else:\n",
                "    from ultralytics import YOLO\n",
                "    # Load optimized PyTorch model\n",
                "    model = YOLO('yolov8n.pt')\n",
                "\n",
                "# Set optimized parameters\n",
                "INPUT_SIZE = (320, 320)  # Reduced resolution\n",
                "CONF_THRESHOLD = 0.25    # Adjusted confidence threshold\n"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "def preprocess_image(frame):\n",
                "    \"\"\"Optimize image preprocessing for memory efficiency.\"\"\"\n",
                "    # Resize with reduced memory footprint\n",
                "    frame = cv2.resize(frame, INPUT_SIZE, interpolation=cv2.INTER_AREA)\n",
                "    \n",
                "    # Normalize using integer arithmetic when possible\n",
                "    frame = frame.astype(np.float32) / 255.0\n",
                "    return frame\n",
                "\n",
                "def process_frame(frame):\n",
                "    \"\"\"Memory-efficient frame processing.\"\"\"\n",
                "    frame = preprocess_image(frame)\n",
                "    \n",
                "    if config.device_type == 'raspberry-pi':\n",
                "        # TFLite inference\n",
                "        input_details = interpreter.get_input_details()\n",
                "        output_details = interpreter.get_output_details()\n",
                "        \n",
                "        interpreter.set_tensor(input_details[0]['index'], np.expand_dims(frame, 0))\n",
                "        interpreter.invoke()\n",
                "        results = interpreter.get_tensor(output_details[0]['index'])\n",
                "    else:\n",
                "        # PyTorch inference\n",
                "        results = model(frame, conf=CONF_THRESHOLD)[0]\n",
                "    \n",
                "    return results\n",
                "\n",
                "def run_inference(video_path):\n",
                "    \"\"\"Memory-efficient video processing.\"\"\"\n",
                "    cap = cv2.VideoCapture(video_path)\n",
                "    box_annotator = BoxAnnotator()\n",
                "    \n",
                "    try:\n",
                "        while cap.isOpened():\n",
                "            ret, frame = cap.read()\n",
                "            if not ret:\n",
                "                break\n",
                "                \n",
                "            # Monitor resources\n",
                "            metrics = monitor.collect_metrics()\n",
                "            warnings = monitor.check_thresholds(metrics)\n",
                "            \n",
                "            if warnings:\n",
                "                print(\"Resource warnings:\", warnings)\n",
                "                continue  # Skip frame if resources are constrained\n",
                "            \n",
                "            # Process frame\n",
                "            results = process_frame(frame)\n",
                "            \n",
                "            # Clear unused variables to manage memory\n",
                "            del frame\n",
                "            \n",
                "    finally:\n",
                "        cap.release()\n",
                "        # Clean up resources\n",
                "        if 'interpreter' in locals():\n",
                "            del interpreter\n"
            ],
            "execution_count": null,
            "outputs": []
        }
    ]
}
